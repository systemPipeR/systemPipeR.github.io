---
title: "How to run a Workflow" 
author: "Author: Daniela Cassol (danielac@ucr.edu) and Thomas Girke (thomas.girke@ucr.edu)"
date: "Last update: 29 April, 2022" 
output:
  BiocStyle::html_document:
    toc_float: true
    code_folding: show
  BiocStyle::pdf_document: default
package: systemPipeR
vignette: |
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{systemPipeR: Workflow design and reporting generation environment}
  %\VignetteEngine{knitr::rmarkdown}
fontsize: 14pt
bibliography: bibtex.bib
editor_options: 
  chunk_output_type: console
type: docs
weight: 3
---

<!--
- Compile from command-line
Rscript -e "rmarkdown::render('systemPipeR.Rmd', c('BiocStyle::html_document'), clean=F); knitr::knit('systemPipeR.Rmd', tangle=TRUE)"; Rscript ../md2jekyll.R systemPipeR.knit.md 2; Rscript -e "rmarkdown::render('systemPipeR.Rmd', c('BiocStyle::pdf_document'))"
-->

<script type="text/javascript">
document.addEventListener("DOMContentLoaded", function() {
  document.querySelector("h1").className = "title";
});
</script>
<script type="text/javascript">
document.addEventListener("DOMContentLoaded", function() {
  var links = document.links;  
  for (var i = 0, linksLength = links.length; i < linksLength; i++)
    if (links[i].hostname != window.location.hostname)
      links[i].target = '_blank';
});
</script>



# Project initialization

To create a Workflow within _`systemPipeR`_, we can start by defining an empty
container and checking the directory structure:


```r
sal <- SPRproject(projPath = tempdir())
```

```
## Creating directory:  /tmp/RtmpUU3S1k/data 
## Creating directory:  /tmp/RtmpUU3S1k/param 
## Creating directory:  /tmp/RtmpUU3S1k/results 
## Creating directory '/tmp/RtmpUU3S1k/.SPRproject'
## Creating file '/tmp/RtmpUU3S1k/.SPRproject/SYSargsList.yml'
```

```
## Your current working directory is different from the directory chosen for the Project Workflow.
## For accurate location of the files and running the Workflow, please set the working directory to 
## 'setwd('/tmp/RtmpUU3S1k')'
```

Internally, `SPRproject` function will create a hidden folder called `.SPRproject`,
by default, to store all the log files.
A `YAML` file, here called `SYSargsList.yml`, has been created, which initially
contains the basic location of the project structure; however, every time the 
workflow object `sal` is updated in R, the new information will also be store in this 
flat-file database for easy recovery.
If you desire different names for the logs folder and the `YAML` file, these can 
be modified as follows:


```r
sal <- SPRproject(logs.dir = ".SPRproject", sys.file = ".SPRproject/SYSargsList.yml")
```

Also, this function will check and/or create the basic folder structure if missing, 
which means `data`, `param`, and `results` folder, as described [here](#dir). 
If the user wants to use a different names for these directories, can be specified 
as follows:


```r
sal <- SPRproject(data = "data", param = "param", results = "results")
```

It is possible to separate all the R objects created within the workflow analysis 
from the current environment. `SPRproject` function provides the option to create 
a new environment, and in this way, it is not overwriting any object you may want
to have at your current section. 


```r
sal <- SPRproject(envir = new.env())
```

In this stage, the object `sal` is a empty container, except for the project information. The project information can be accessed by the `projectInfo` method:


```r
sal
```

```
## Instance of 'SYSargsList': 
##  No workflow steps added
```

```r
projectInfo(sal)
```

```
## $project
## [1] "/tmp/RtmpUU3S1k"
## 
## $data
## [1] "data"
## 
## $param
## [1] "param"
## 
## $results
## [1] "results"
## 
## $logsDir
## [1] ".SPRproject"
## 
## $sysargslist
## [1] ".SPRproject/SYSargsList.yml"
```

Also, the `length` function will return how many steps this workflow contains and
in this case it is empty, as follow:


```r
length(sal)
```

```
## [1] 0
```

# Workflow Design 

_`systemPipeR`_ workflows can be designed and built from start to finish with a 
single command, importing from an R Markdown file or stepwise in interactive 
mode from the R console. 
In the [next section](#appendstep), we will demonstrate how to build the workflow in an
interactive mode, and in the [following section](#importWF), we will show how to build from a 
file. 

New workflows are constructed, or existing ones modified, by connecting each 
step via `appendStep` method. Each `SYSargsList` instance contains instructions 
needed for processing a set of input files with a specific command-line or R 
software, as well as the paths to the corresponding outfiles generated by a 
particular tool/step. 

To build R code based step, the constructor function `Linewise` is used. 
For more details about this S4 class container, see [here](#linewise). 

## Build workflow interactive {#appendstep}

This tutorial shows a very simple example for describing and explaining all main 
features available within systemPipeR to design, build, manage, run, and 
visualize the workflow. In summary, we are exporting a dataset to multiple 
files, compressing and decompressing each one of the files, and importing to R, 
and finally performing a statistical analysis. 

In the previous section, we initialize the project by building the `sal` object.
Until this moment, the container has no steps:


```r
sal
```

```
## Instance of 'SYSargsList': 
##  No workflow steps added
```

Next, we need to populate the object created with the first step in the
workflow.

### Adding the first step 

The first step is R code based, and we are splitting the `iris` dataset by `Species`
and for each `Species` will be saved on file. Please note that this code will
not be executed now; it is just store in the container for further execution. 

This constructor function requires the `step_name` and the R-based code under 
the `code` argument. 
The R code should be enclosed by braces (`{}`) and separated by a new line. 


```r
appendStep(sal) <- LineWise(code = {
    mapply(function(x, y) write.csv(x, y), split(iris, factor(iris$Species)), file.path("results",
        paste0(names(split(iris, factor(iris$Species))), ".csv")))
}, step_name = "export_iris")
```

For a brief overview of the workflow, we can check the object as follows:


```r
sal
```

```
## Instance of 'SYSargsList': 
##     WF Steps:
##        1. export_iris --> Status: Pending
## 
```

Also, for printing and double-check the R code in the step, we can use the 
`codeLine` method:


```r
codeLine(sal)
```

```
## export_iris
##     mapply(function(x, y) write.csv(x, y), split(iris, factor(iris$Species)), file.path("results", paste0(names(split(iris, factor(iris$Species))), ".csv")))
```

### Adding more steps

Next, an example of how to compress the exported files using 
[`gzip`](https://www.gnu.org/software/gzip/) command-line. 

The constructor function creates an `SYSargsList` S4 class object using data from
three input files:

    - CWL command-line specification file (`wf_file` argument);
    - Input variables (`input_file` argument);
    - Targets file (`targets` argument).

In CWL, files with the extension `.cwl` define the parameters of a chosen
command-line step or workflow, while files with the extension `.yml` define the
input variables of command-line steps. 

The `targets` file is optional for workflow steps lacking `input` files. The connection 
between `input` variables and the `targets` file is defined under the `inputvars` 
argument. It is required a `named vector`, where each element name needs to match
with column names in the `targets` file, and the value must match the names of 
the `input` variables defined in the `*.yml` files (see Figure \@ref(fig:sprCWL)). 

A detailed description of the dynamic between `input` variables and `targets` 
files can be found [here](#cwl_targets). 
In addition, the CWL syntax overview can be found [here](#cwl). 

Besides all the data form `targets`, `wf_file`, `input_file` and `dir_path` arguments,
`SYSargsList` constructor function options include: 

  - `step_name`: a unique *name* for the step. This is not mandatory; however, 
    it is highly recommended. If no name is provided, a default `step_x`, where
    `x` reflects the step index, will be added. 
  - `dir`: this option allows creating an exclusive subdirectory for the step 
    in the workflow. All the outfiles and log files for this particular step will 
    be generated in the respective folders.
  - `dependency`: after the first step, all the additional steps appended to 
    the workflow require the information of the dependency tree. 

The `appendStep<-` method is used to append a new step in the workflow.


```r
targetspath <- system.file("extdata/cwl/gunzip", "targets_gunzip.txt", package = "systemPipeR")
appendStep(sal) <- SYSargsList(step_name = "gzip", targets = targetspath, dir = TRUE,
    wf_file = "gunzip/workflow_gzip.cwl", input_file = "gunzip/gzip.yml", dir_path = system.file("extdata/cwl",
        package = "systemPipeR"), inputvars = c(FileName = "_FILE_PATH_", SampleName = "_SampleName_"),
    dependency = "export_iris")
```

Note: This will not work if the `gzip` is not available on your system 
(installed and exported to PATH) and may only work on Windows systems using PowerShell. 

For a overview of the workflow, we can check the object as follows:


```r
sal
```

```
## Instance of 'SYSargsList': 
##     WF Steps:
##        1. export_iris --> Status: Pending
##        2. gzip --> Status: Pending 
##            Total Files: 3 | Existing: 0 | Missing: 3 
##          2.1. gzip
##              cmdlist: 3 | Pending: 3
## 
```

Note that we have two steps, and it is expected three files from the second step.
Also, the workflow status is *Pending*, which means the workflow object is 
rendered in R; however, we did not execute the workflow yet. 
In addition to this summary, it can be observed this step has three command lines. 

For more details about the command-line rendered for each target file, it can be 
checked as follows: 


```r
cmdlist(sal, step = "gzip")
```

```
## $gzip
## $gzip$SE
## $gzip$SE$gzip
## [1] "gzip -c  results/setosa.csv > results/SE.csv.gz"
## 
## 
## $gzip$VE
## $gzip$VE$gzip
## [1] "gzip -c  results/versicolor.csv > results/VE.csv.gz"
## 
## 
## $gzip$VI
## $gzip$VI$gzip
## [1] "gzip -c  results/virginica.csv > results/VI.csv.gz"
```

#### Using the `outfiles` for the next step

For building this step, all the previous procedures are being used to append the 
next step. However, here, we can observe power features that build the 
connectivity between steps in the workflow.

In this example, we would like to use the outfiles from *gzip* Step, as
input from the next step, which is the *gunzip*. In this case, let's look at the 
outfiles from the first step:


```r
outfiles(sal)
```

```
## $export_iris
## DataFrame with 0 rows and 0 columns
## 
## $gzip
## DataFrame with 3 rows and 1 column
##            gzip_file
##          <character>
## SE results/SE.csv.gz
## VE results/VE.csv.gz
## VI results/VI.csv.gz
```

The column we want to use is "gzip_file". For the argument `targets` in the 
`SYSargsList` function, it should provide the name of the correspondent step in
the Workflow and which `outfiles` you would like to be incorporated in the next 
step. 
The argument `inputvars` allows the connectivity between `outfiles` and the 
new `targets` file. Here, the name of the previous `outfiles` should be provided 
it. Please note that all `outfiles` column names must be unique.

It is possible to keep all the original columns from the `targets` files or remove
some columns for a clean `targets` file.
The argument `rm_targets_col` provides this flexibility, where it is possible to
specify the names of the columns that should be removed. If no names are passing
here, the new columns will be appended. 


```r
appendStep(sal) <- SYSargsList(step_name = "gunzip", targets = "gzip", dir = TRUE,
    wf_file = "gunzip/workflow_gunzip.cwl", input_file = "gunzip/gunzip.yml", dir_path = system.file("extdata/cwl",
        package = "systemPipeR"), inputvars = c(gzip_file = "_FILE_PATH_", SampleName = "_SampleName_"),
    rm_targets_col = "FileName", dependency = "gzip")
```

We can check the targets automatically create for this step, 
based on the previous `outfiles`:


```r
targetsWF(sal[3])
```

```
## $gunzip
## DataFrame with 3 rows and 2 columns
##            gzip_file  SampleName
##          <character> <character>
## SE results/SE.csv.gz          SE
## VE results/VE.csv.gz          VE
## VI results/VI.csv.gz          VI
```

We can also check all the expected `outfiles` for this particular step, as follows:


```r
outfiles(sal[3])
```

```
## $gunzip
## DataFrame with 3 rows and 1 column
##       gunzip_file
##       <character>
## SE results/SE.csv
## VE results/VE.csv
## VI results/VI.csv
```

Now, we can observe that the third step has been added and contains one substep.


```r
sal
```

```
## Instance of 'SYSargsList': 
##     WF Steps:
##        1. export_iris --> Status: Pending
##        2. gzip --> Status: Pending 
##            Total Files: 3 | Existing: 0 | Missing: 3 
##          2.1. gzip
##              cmdlist: 3 | Pending: 3
##        3. gunzip --> Status: Pending 
##            Total Files: 3 | Existing: 0 | Missing: 3 
##          3.1. gunzip
##              cmdlist: 3 | Pending: 3
## 
```

In addition, we can access all the command lines for each one of the substeps. 


```r
cmdlist(sal["gzip"], targets = 1)
```

```
## $gzip
## $gzip$SE
## $gzip$SE$gzip
## [1] "gzip -c  results/setosa.csv > results/SE.csv.gz"
```

#### Getting data from a workflow instance 

The final step in this simple workflow is an R code step. For that, we are using
the `LineWise` constructor function as demonstrated above. 

One interesting feature showed here is the `getColumn` method that allows 
extracting the information for a workflow instance. Those files can be used in
an R code, as demonstrated below. 


```r
getColumn(sal, step = "gunzip", "outfiles")
```

```
##               SE               VE               VI 
## "results/SE.csv" "results/VE.csv" "results/VI.csv"
```


```r
appendStep(sal) <- LineWise(code = {
    df <- lapply(getColumn(sal, step = "gunzip", "outfiles"), function(x) read.delim(x,
        sep = ",")[-1])
    df <- do.call(rbind, df)
    stats <- data.frame(cbind(mean = apply(df[, 1:4], 2, mean), sd = apply(df[, 1:4],
        2, sd)))
    stats$species <- rownames(stats)

    plot <- ggplot2::ggplot(stats, ggplot2::aes(x = species, y = mean, fill = species)) +
        ggplot2::geom_bar(stat = "identity", color = "black", position = ggplot2::position_dodge()) +
        ggplot2::geom_errorbar(ggplot2::aes(ymin = mean - sd, ymax = mean + sd),
            width = 0.2, position = ggplot2::position_dodge(0.9))
}, step_name = "iris_stats", dependency = "gzip")
```

## Build workflow from a {R Markdown} {#importWF}

The precisely same workflow can be created by importing the steps from an 
R Markdown file.
As demonstrated above, it is required to initialize the project with `SPRproject` function. 

`importWF` function will scan and import all the R chunk from the R Markdown file 
and build all the workflow instances. Then, each R chuck in the file will be 
converted in a workflow step. 

























































































